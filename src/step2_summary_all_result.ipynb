{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "  0%|          | 0/3475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip: AFTF-ds=PictureClass_l-d=1-nh=5-r=40-bs=128-ls=0.015-label=hand\n",
      "skip: FTF-ds=PictureClass_n-d=2-nh=5-r=40-bs=128-ls=0.00015-label=relationship\n",
      "no ckpt: AFTF-ds=PictureClass_l-d=3-nh=19-r=5-bs=128-ls=5e-05-label=relationship\n",
      "skip: FTF-ds=PictureRating_d-d=3-nh=8-r=1-bs=256-ls=0.0015-label=hand\n",
      "skip: FTF-ds=PictureClass_l-d=1-nh=19-r=1-bs=256-ls=0.00015-label=relationship\n",
      "skip: FTF-ds=PictureRating_l-d=2-nh=11-r=10-bs=256-ls=0.015-label=relationship\n",
      "skip: FTF-ds=PictureClass_n-d=1-nh=8-r=1-bs=128-ls=0.03-label=relationship\n",
      "no ckpt: baseline_TFe-ds=PictureClass_t-d=2-nh=5-bs=128-ls=5e-05-label=relationship\n",
      "processing: baseline_TFe-ds=PictureRating_t-d=1-nh=3-bs=128-ls=0.015-label=hand\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/3475 [00:12<1:22:17,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip: FTF-ds=PictureRating_d-d=1-nh=5-r=10-bs=256-ls=0.00015-label=emotion\n",
      "skip: FTF-ds=PictureRating_t-d=1-nh=11-r=1-bs=128-ls=0.003-label=relationship\n",
      "skip: FTF-ds=PictureClass_t-d=1-nh=5-r=5-bs=128-ls=0.015-label=relationship\n",
      "no ckpt: AFTF-ds=PictureRating_l-d=1-nh=11-r=1-bs=128-ls=0.015-label=relationship\n",
      "skip: AFTF-ds=PictureClass_l-d=1-nh=19-r=40-bs=128-ls=5e-05-label=relationship\n",
      "processing: baseline_TFe-ds=PictureRating_t-d=2-nh=11-bs=128-ls=0.0015-label=relationship\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3475 [00:34<2:25:14,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ckpt: AFTF-ds=PictureClass_l-d=1-nh=5-r=1-bs=128-ls=0.0015-label=hand\n",
      "no ckpt: AFTF-ds=PictureClass_l-d=2-nh=19-r=1-bs=128-ls=5e-05-label=emotion\n",
      "skip: FTF-ds=PictureClass_t-d=3-nh=5-r=5-bs=128-ls=0.0015-label=relationship\n",
      "no ckpt: baseline_TFe-ds=PictureRating_t-d=1-nh=3-bs=128-ls=0.003-label=emotion\n",
      "skip: AFTF-ds=PictureClass_l-d=2-nh=5-r=40-bs=128-ls=0.003-label=emotion\n",
      "processing: baseline_TFe-ds=PictureClass_t-d=1-nh=19-bs=128-ls=0.015-label=relationship\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n",
      "The pipeline is not setup, will use identity transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/3475 [00:48<2:19:45,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ckpt: AFTF-ds=PictureRating_l-d=1-nh=3-r=5-bs=128-ls=0.015-label=hand\n",
      "no ckpt: AFTF-ds=PictureClass_l-d=2-nh=19-r=40-bs=128-ls=5e-05-label=relationship\n",
      "skip: FTF-ds=PictureRating_d-d=2-nh=8-r=10-bs=256-ls=5e-05-label=hand\n",
      "no ckpt: FTF-ts=0.3-nr=3-d=2-nh=8bs=128-ls=0.00015-label=relationship\n",
      "skip: FTF-ds=PictureRating_d-d=1-nh=8-r=40-bs=256-ls=0.00015-label=relationship\n",
      "skip: FTF-ds=PictureRating_l-d=3-nh=11-r=40-bs=256-ls=0.003-label=relationship\n",
      "skip: FTF-ds=PictureRating_l-d=1-nh=11-r=5-bs=256-ls=0.00015-label=emotion\n",
      "skip: FTF-ds=PictureRating_l-d=3-nh=11-r=10-bs=256-ls=0.015-label=relationship\n",
      "skip: FTF-ds=PictureClass_d-d=3-nh=5-r=40-bs=256-ls=0.015-label=relationship\n",
      "skip: FTF-ds=PictureRating_n-d=3-nh=5-r=1-bs=128-ls=0.0015-label=relationship\n",
      "no ckpt: AFTF-ds=PictureClass_l-d=1-nh=19-r=1-bs=128-ls=0.03-label=hand\n",
      "skip: FTF-ds=PictureClass_n-d=1-nh=5-r=40-bs=128-ls=0.03-label=relationship\n",
      "skip: AFTF-ds=PictureRating_l-d=1-nh=11-r=10-bs=128-ls=5e-05-label=relationship\n",
      "no ckpt: figures\n",
      "skip: FTF-ds=PictureClass_d-d=2-nh=8-r=40-bs=256-ls=0.003-label=hand\n",
      "no ckpt: AFTF-ds=PictureClass_l-d=3-nh=5-r=1-bs=128-ls=0.003-label=hand\n",
      "processing: LSTM-ds=PictureClass_t-d=2-nh=19bs=128-ls=0.0015-label=hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 37/3475 [00:49<1:15:54,  1.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(work_dir, experiment_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mckpts\u001b[39m\u001b[38;5;124m'\u001b[39m, ckpt_path)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# read config details\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# load config\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m model, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfing_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path)\n\u001b[1;32m     96\u001b[0m res \u001b[38;5;241m=\u001b[39m model_inference(model, test_loader)\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mload_model_data\u001b[0;34m(config_path, ckpt_path, confing_function)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_data\u001b[39m(config_path, ckpt_path,confing_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     26\u001b[0m     data_module, model \u001b[38;5;241m=\u001b[39m prepare_inference(config_path, ckpt_path, confing_function\u001b[38;5;241m=\u001b[39mconfing_function)\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m data_module\u001b[38;5;241m.\u001b[39mtest_dataloader()\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, test_loader\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/data_interface.py:40\u001b[0m, in \u001b[0;36mDataInterface.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m stage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# prevent datasets from being multiply created\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_multipe_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_multipe_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_cfg\u001b[38;5;241m.\u001b[39mval)\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/data_interface.py:32\u001b[0m, in \u001b[0;36mDataInterface.get_multipe_dataset\u001b[0;34m(self, dataset_cfg)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     dataset_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultiple_key\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasets\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/builder.py:13\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_dataset\u001b[39m(cfg):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''build dataset with given config'''\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASETS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/utils/config.py:88\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype must be a str or valid type, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Normal TypeError does not print class name.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/dataset/fNIRS_Emo_CL_all_between_subject.py:40\u001b[0m, in \u001b[0;36mfNIRS_Emo_CL_all_between_subject.__init__\u001b[0;34m(self, data_root, test_size, dataset_random_state, temp_save_folder, tier, sampler, pipeline, label, normalize_mode, minmax_value, subject_split, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m             data_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     28\u001b[0m             test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m             subject_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;241m=\u001b[39m Compose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/dataset/fNIRS_Emo_CL_all_between_subject.py:66\u001b[0m, in \u001b[0;36mfNIRS_Emo_CL_all_between_subject.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m pair_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_data[hand][relationship_label][emotion_label]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m isubj, subj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_data[hand][relationship_label][emotion_label][pair_id]):\n\u001b[0;32m---> 66\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_data[hand][relationship_label][emotion_label][pair_id][isubj] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_data_table()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_data()\n",
      "File \u001b[0;32m/data/xiaowjia/Friends_fNIRS/src/shallowmind/src/data/dataset/fNIRS_Emo_CL_all_between_subject.py:76\u001b[0m, in \u001b[0;36mfNIRS_Emo_CL_all_between_subject.normalize\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mdata: [n_channels, data_length]\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m data\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m/\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminmax_value[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminmax_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminmax_value[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/data/xiaowjia/miniconda3/envs/dl_pl/lib/python3.10/site-packages/numpy/core/_methods.py:264\u001b[0m, in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_std\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    263\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 264\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    268\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39msqrt(ret, out\u001b[38;5;241m=\u001b[39mret)\n",
      "File \u001b[0;32m/data/xiaowjia/miniconda3/envs/dl_pl/lib/python3.10/site-packages/numpy/core/_methods.py:232\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    227\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean \u001b[38;5;241m/\u001b[39m rcount\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marrmean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[1;32m    235\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, x, out\u001b[38;5;241m=\u001b[39mx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from shallowmind.src.model import ModelInterface\n",
    "from shallowmind.src.data import DataInterface\n",
    "from shallowmind.api.infer import prepare_inference\n",
    "from shallowmind.src.utils import load_config\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "def config_function(config):\n",
    "    config.data['train']['data_root'] = config.data['train']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "    config.data['val']['data_root'] = config.data['val']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "    config.data['test']['data_root'] = config.data['test']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "\n",
    "    config.data['train']['temp_save_folder'] = config.data['train']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "    config.data['val']['temp_save_folder'] = config.data['val']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "    config.data['test']['temp_save_folder'] = config.data['test']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "    return config\n",
    "\n",
    "def load_model_data(config_path, ckpt_path,confing_function=None):\n",
    "    data_module, model = prepare_inference(config_path, ckpt_path, confing_function=confing_function)\n",
    "    data_module.setup()\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    return model, test_loader\n",
    "\n",
    "def model_inference(model, test_loader, device='cuda', metrics=['accuracy', 'recall', 'precision', 'f1', 'roc_auc', 'pr_auc']):\n",
    "    # inference\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    data_table = test_loader.dataset.data_table\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for batch_id,d in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            data = {'seq': d[0]['seq'].to(device),}\n",
    "            label = d[1].to(device)\n",
    "            out = model.model.forward(data, label) \n",
    "            if len(out) == 2:\n",
    "                loss, pred = out[0], out[1]\n",
    "            elif len(out) == 3:\n",
    "                loss, pred, att = out[0], out[1], out[2]\n",
    "            pred = pred.argmax(dim=1)\n",
    "            predictions.append(pred.cpu().numpy())\n",
    "            labels.append(label.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    labels = np.concatenate(labels)\n",
    "    res = pd.DataFrame(columns=metrics, index=[0])\n",
    "    for metric in metrics:\n",
    "        if metric == 'accuracy':\n",
    "            res[metric] = accuracy_score(labels, predictions)\n",
    "        elif metric == 'recall':\n",
    "            res[metric] = recall_score(labels, predictions)\n",
    "        elif metric == 'precision':\n",
    "            res[metric] = precision_score(labels, predictions)\n",
    "        elif metric == 'f1':\n",
    "            res[metric] = f1_score(labels, predictions)\n",
    "        elif metric == 'roc_auc':\n",
    "            res[metric] = roc_auc_score(labels, predictions)\n",
    "        elif metric == 'pr_auc':\n",
    "            res[metric] = average_precision_score(labels, predictions)\n",
    "    return res\n",
    "\n",
    "\n",
    "work_dir = '/data/xiaowjia/Friends_fNIRS/work_dir'\n",
    "save_path = '/data/xiaowjia/Friends_fNIRS/output/results.csv'\n",
    "if os.path.exists(save_path):\n",
    "    res_table = pd.read_csv(save_path)\n",
    "else:\n",
    "    res_table = pd.DataFrame(columns=['experiment_path', 'dataset_type', 'dataset_label', 'dataset_name', 'base_lr', 'batch_size', 'model_name', 'model_type', 'num_heads', 'depth', 'num_rules']+['accuracy', 'recall', 'precision', 'f1', 'roc_auc', 'pr_auc'])\n",
    "\n",
    "experiments_paths = [f for f in os.listdir(work_dir)]\n",
    "for experiment_path in tqdm(experiments_paths, total=len(experiments_paths)):\n",
    "    try:\n",
    "        if not os.path.exists(os.path.join(work_dir, experiment_path, 'ckpts','last.ckpt')): \n",
    "            print(f'no ckpt: {experiment_path}')\n",
    "            continue\n",
    "        if experiment_path in res_table['experiment_path'].values: \n",
    "            print(f'skip: {experiment_path}')\n",
    "            continue\n",
    "        print(f'processing: {experiment_path}')\n",
    "        config_poth = [f for f in os.listdir(os.path.join(work_dir, experiment_path)) if f.endswith('.py')][0]\n",
    "        config_path = os.path.join(work_dir, experiment_path, config_poth)\n",
    "        ckpt_path = [f for f in os.listdir(os.path.join(work_dir, experiment_path, 'ckpts')) if not f.startswith('last')]\n",
    "        ckpt_path = sorted(ckpt_path, key=lambda x: float(x.split('=')[-1].split('.')[0]), reverse=True)[0]\n",
    "        ckpt_path = os.path.join(work_dir, experiment_path, 'ckpts', ckpt_path)\n",
    "        # read config details\n",
    "\n",
    "        # load config\n",
    "        model, test_loader = load_model_data(config_path, ckpt_path, confing_function=config_function)\n",
    "        config = load_config(config_path)\n",
    "        res = model_inference(model, test_loader)\n",
    "\n",
    "        # add para to res\n",
    "        res['experiment_path'] = experiment_path\n",
    "\n",
    "        dataset_type = config['dataset_para']['type']\n",
    "        res['dataset_type'] = dataset_type\n",
    "\n",
    "        dataset_label = config['dataset_para']['label']\n",
    "        res['dataset_label'] = dataset_label\n",
    "\n",
    "        dataset_name = config['dataset_name']\n",
    "        res['dataset_name'] = dataset_name\n",
    "\n",
    "        base_lr = config['base_lr']\n",
    "        res['base_lr'] = base_lr\n",
    "\n",
    "        batch_size = config['batch_size']\n",
    "        res['batch_size'] = batch_size\n",
    "\n",
    "        model_name = config['model']['type']\n",
    "        res['model_name'] = model_name\n",
    "\n",
    "        model_type = config['model_para']['encoder_type']\n",
    "        res['model_type'] = model_type\n",
    "\n",
    "        num_heads = config['model_para']['num_heads']\n",
    "        res['num_heads'] = num_heads\n",
    "\n",
    "        depth = config['model_para']['depth']\n",
    "        res['depth'] = depth\n",
    "\n",
    "        try:\n",
    "            num_rules = config['model_para']['num_rules']\n",
    "            res['num_rules'] = num_rules\n",
    "        except:\n",
    "            res['num_rules'] = 0\n",
    "        \n",
    "        res_table = pd.concat([res_table, res], axis=0)\n",
    "        res_table.to_csv(save_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f'failed: {experiment_path}: {e}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: /data/xiaowjia/Friends_fNIRS/work_dir/baseline_TFe-ds=PictureRating_t-d=1-nh=3-bs=128-ls=0.015-label=hand/tramsformer_num_heads3_dataset_name=PictureRating_label=hand_base_lr=1.5e-2_depth=1_batch_size=128.py): {'data_root': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', 'work_dir': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/Friends_fNIRS_Fuzzy/work_dir', 'dataset_name': 'PictureRating', 'dataset_para': {'type': 'fNIRS_Emo_CL_all_between_subject', 'data_root': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/step1_PPCS_0.01_0.2PictureRating_data.pkl', 'test_size': 0.3, 'dataset_random_state': 42, 'temp_save_folder': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/temp', 'label': 'hand', 'subject_split': 'between'}, 'base_lr': 0.015, 'batch_size': 128, 'lr': 0.015, 'model_para': {'img_size': (40, 33), 'num_heads': 3, 'depth': 1, 'cl_embed_dim': 64, 'encoder_type': 'Transformer', 'dropout': 0.3, 'model_ckpt': None, 'fixed': False}, 'exp_name': 'baseline_TFe-ds=PictureRating_t-d=1-nh=3-bs=128-ls=0.015-label=hand', 'evaluation': {'metrics': [{'type': 'TorchMetrics', 'metric_name': 'Accuracy', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'Precision', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'Recall', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'F1Score', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}]}, 'model': {'type': 'EEGTransClassifer_explainable', 'pretrained': False, 'evaluation': {'metrics': [{'type': 'TorchMetrics', 'metric_name': 'Accuracy', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'Precision', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'Recall', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}, {'type': 'TorchMetrics', 'metric_name': 'F1Score', 'multi_label': False, 'num_classes': 2, 'prob': False, 'task': 'multiclass'}]}, 'img_size': (40, 33), 'num_heads': 3, 'depth': 1, 'cl_embed_dim': 64, 'encoder_type': 'Transformer', 'dropout': 0.3, 'model_ckpt': None, 'fixed': False}, 'data': {'train_batch_size': 128, 'val_batch_size': 128, 'test_batch_size': 128, 'num_workers': 24, 'train': {'sampler': None, 'tier': 'train', 'type': 'fNIRS_Emo_CL_all_between_subject', 'data_root': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/step1_PPCS_0.01_0.2PictureRating_data.pkl', 'test_size': 0.3, 'dataset_random_state': 42, 'temp_save_folder': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/temp', 'label': 'hand', 'subject_split': 'between'}, 'val': {'sampler': 'SequentialSampler', 'tier': 'val', 'type': 'fNIRS_Emo_CL_all_between_subject', 'data_root': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/step1_PPCS_0.01_0.2PictureRating_data.pkl', 'test_size': 0.3, 'dataset_random_state': 42, 'temp_save_folder': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/temp', 'label': 'hand', 'subject_split': 'between'}, 'test': {'sampler': 'SequentialSampler', 'tier': 'val', 'type': 'fNIRS_Emo_CL_all_between_subject', 'data_root': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/step1_PPCS_0.01_0.2PictureRating_data.pkl', 'test_size': 0.3, 'dataset_random_state': 42, 'temp_save_folder': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/temp', 'label': 'hand', 'subject_split': 'between'}}, 'resume_from': None, 'cudnn_benchmark': True, 'optimization': {'type': 'epoch', 'max_iters': 800, 'optimizer': {'type': 'AdamW', 'lr': 0.015, 'weight_decay': 0.05, 'betas': (0.9, 0.95), 'eps': 1e-08}, 'scheduler': {'type': 'WarmupCosineDecayLR', 'warmup_epochs': 80, 'last_epoch': -1}}, 'log': {'project_name': 'fNIRS_Emo', 'work_dir': '/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/Friends_fNIRS_Fuzzy/work_dir', 'exp_name': 'baseline_TFe-ds=PictureRating_t-d=1-nh=3-bs=128-ls=0.015-label=hand', 'logger_interval': 200, 'monitor': 'val_f1_score', 'logger': [{'type': 'comet', 'key': 'EOxad0Dbwx7UdmzxjwC2rx38H'}, {'type': 'csv'}], 'checkpoint': {'type': 'ModelCheckpoint', 'top_k': 3, 'mode': 'max', 'verbose': False, 'save_last': True}, 'earlystopping': {'mode': 'max', 'strict': False, 'patience': 30, 'min_delta': 0.0005, 'check_finite': True, 'verbose': True}}, 'base_name': 'tramsformer_num_heads3_dataset_name=PictureRating_label=hand_base_lr=1.5e-2_depth=1_batch_size=128.py'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/data/xiaowjia/Friends_fNIRS/work_dir/AFTF-ds=PictureClass_l-d=1-nh=5-r=1-bs=128-ls=0.003-label=hand/FuzzyTramsformer_ALL_num_rules1_num_heads5_dataset_name=PictureClass_label=hand_base_lr=3e-3_depth=1_batch_size=128.py'\n",
    "config = load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data['train']['data_root'] = config.data['train']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "config.data['val']['data_root'] = config.data['val']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "config.data['test']['data_root'] = config.data['test']['data_root'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "\n",
    "config.data['train']['temp_save_folder'] = config.data['train']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "config.data['val']['temp_save_folder'] = config.data['val']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "config.data['test']['temp_save_folder'] = config.data['test']['temp_save_folder'].replace('/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset', '/data/xiaowjia/Friends_fNIRS/data')\n",
    "'/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset/temp/data_table_between_train.csv'\n",
    "'/projects/CIBCIGroup/00DataUploading/Liang/fuzzy_fnirs/dataset'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config.data['train']['data_root'])\n",
    "print(config.data['val']['data_root'])\n",
    "print(config.data['test']['data_root'])\n",
    "print(config.data['train']['temp_save_folder'])\n",
    "print(config.data['val']['temp_save_folder'])\n",
    "print(config.data['test']['temp_save_folder'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
